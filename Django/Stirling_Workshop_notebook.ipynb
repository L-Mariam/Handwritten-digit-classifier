{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5FlqRFGP-HZ"
      },
      "source": [
        "#### **Stirling WorkShop**:\n",
        "\n",
        "\n",
        "\n",
        "## Build, Train, and Deploy a Handwritten Digit Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E45Xf8RnP-Hd"
      },
      "source": [
        "<img width=160 src=\"https://drive.google.com/uc?export=view&id=1u5KB1ZRk0uYXZHIepMtnsVgcpROyIFJ0\"/>\n",
        "<img src=\"https://app.piratepx.com/ship?p=6f6529da-9ed0-4188-a602-070f75691c96&i=qtf-free-lesson-mnist\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OU1eMXHP-Hf"
      },
      "source": [
        "**Table of Contents**\n",
        "\n",
        "1. [Setup](#setup)\n",
        "2. [Prepare the Data](#prepare)\n",
        "3. [Build the Model](#build)\n",
        "4. [Train the Model](#train)\n",
        "5. [Evaluate the Model](#evaluate)\n",
        "6. [Export to TensorFlow Lite](#export)\n",
        "7. [Deploy with PalletML](#deploy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQEKJ1zkP-Hg"
      },
      "source": [
        "## Setup <a name=\"setup\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXUqxpJCQ2JS"
      },
      "source": [
        "Import TensorFlow and supporting libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wh3qguO2ATL4"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m \u001b[39m# an end-to-end machine learning platform that help us to implement ,train and test our models easily\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \u001b[39m# The fundamental package for scientific computing with Python that helps us to use mathematical functions easily in python\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \u001b[39m# a comprehensive library for creating static, animated, and interactive visualizations in Python\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf # an end-to-end machine learning platform that help us to implement ,train and test our models easily\n",
        "import numpy as np # The fundamental package for scientific computing with Python that helps us to use mathematical functions easily in python\n",
        "import matplotlib.pyplot as plt # a comprehensive library for creating static, animated, and interactive visualizations in Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PRgpC-gxWfk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57nuAmKwP-Hl"
      },
      "source": [
        "## Prepare the data <a name=\"prepare\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_LdJssjP-Hn"
      },
      "source": [
        "Load the MNIST dataset from the built-in Keras [datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) module, then **preprocess** the data by converting the samples from integers to floating-point numbers and scaling the pixel values to a range of 0 to 1.\n",
        "\n",
        "Keras is a high-level API for TensorFlow that enables developers to rapidly build, train, and iterate on machine learning models for various tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SWSwqa_P-Hn",
        "outputId": "0ab029c1-ad9a-4bf5-f1c8-a45eb1ddea61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Image shape: (28, 28, 1)\n",
            "60000 Train samples\n",
            "10000 Test samples\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "print()\n",
        "print('Image shape:', x_train.shape[1:])\n",
        "print(x_train.shape[0], \"Train samples\")\n",
        "print(x_test.shape[0], \"Test samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n2BzOkfP-Ht"
      },
      "source": [
        "Let's look at a sample image and label from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "QjEi6wudP-Hu",
        "outputId": "282fd3fd-adb3-4b37-d647-16df2929c801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa833355f50>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_index =2  # try from 0 to 60000-1\n",
        "sample_image, sample_label = x_train[sample_index], y_train[sample_index]\n",
        "\n",
        "#plt.subplot(1, 1, 1)\n",
        "#plt.axis('off')\n",
        "plt.title('True Label: {}'.format(sample_label))\n",
        "plt.imshow(sample_image.reshape(28, 28), cmap=plt.cm.gray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDrkcZ94P-Hx"
      },
      "source": [
        "## Build the model <a name=\"build\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktj0ObScP-Hy"
      },
      "source": [
        "Here we build a simple **[convolutional neural network](https://developers.google.com/machine-learning/glossary#convolutional-layer) (CNN)** that takes an image of size 28x28 as input, and outputs a list of 10 **predictions**, each representing a confidence that the input image contains the number corresponding to the index of the prediction in the list.\n",
        "\n",
        "Note that because the MNIST dataset is *grayscale*, the images only have 1 color channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "S75UqiCDP-Hy",
        "outputId": "e2538310-4beb-4e4d-e059-b9feb569f2b6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m img_shape \u001b[39m=\u001b[39m (\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m# height x width x channels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      5\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(filters\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39mimg_shape ),\n\u001b[0;32m      6\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m      7\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[0;32m      8\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m      ])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "img_shape = (28, 28, 1) # height x width x channels\n",
        "num_classes = 10\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='', input_shape=img_shape ),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(num_classes, activation='')\n",
        "     ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIsvj-1fP-H1"
      },
      "source": [
        "We then configure the model with a cross entropy **loss function** that works for scalar `y` values (instead of [one-hot encoded](https://developers.google.com/machine-learning/glossary#one-hot-encoding) values), and a standard **optimization algorithm**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynSuPBtfP-H2"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='rmsprop', \n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceT1E0O6P-H7"
      },
      "source": [
        "## Train the model <a name=\"train\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0J14PVkP-H8"
      },
      "source": [
        "We train the model using `Model.fit`, which iterates over the 60k training images in batches of 128, **learning** the features of the data, and adjusting the model parameters to minimize loss. Each iteration over the dataset during training is called an *epoch*, and here we train our model for 5 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok7nUknaP-H8"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, batch_size=, epochs=, verbose=)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8sZQ5sJP-IA"
      },
      "source": [
        "After just 5 epochs your model is over **98% accurate** in classifying images from the training dataset! Now let's test it on images it hasn't seen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYhlCwH1xWfl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhgpVJcBP-IA"
      },
      "source": [
        "## Evaluate the trained model <a name=\"evaluate\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRw_PT0IP-IB"
      },
      "source": [
        "Use the **test set** to evaluate your model on data it's never seen. This is the best way to accurately judge its predictive power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3TR53FwP-IB"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa9qMA7uP-ID"
      },
      "source": [
        "Show a sample prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syIoGDawP-IE"
      },
      "outputs": [],
      "source": [
        "test_index = 10 # try from 0 to 10000-1\n",
        "test_image, test_label = x_test[test_index], y_test[test_index]\n",
        "\n",
        "# Models work with batches of data, so add an extra dimension to the test image\n",
        "# and make a prediction\n",
        "prediction = model.predict(np.expand_dims(test_image, axis=0))\n",
        "predicted_label = np.argmax(prediction)\n",
        "color = 'green' if predicted_label == test_label else 'red'\n",
        "\n",
        "\n",
        "plt.title('Prediction: {}, True: {}'.format(predicted_label, test_label), color=color)\n",
        "plt.imshow(test_image.reshape(28, 28), cmap=plt.cm.gray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cl5SqOWxWfl"
      },
      "source": [
        "# **Now it is time for magic ðŸ¥°**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ib0ZXd7P-IH"
      },
      "source": [
        "## Export the model to TensorFlow Lite <a name=\"export\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2khhUIRP-II"
      },
      "source": [
        "In order to deploy your model to a mobile device, we need to convert it to a **TensorFlow Lite** model and export it as a file.  \n",
        "\n",
        "We also need to export a set of labels corresponding to the numerical output of our model so the mobile app knows how to display the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFFczj32P-IL"
      },
      "source": [
        "Save the TensorFlow Lite model as binary file with a conventional `.tflite` extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP-0fndIP-II"
      },
      "outputs": [],
      "source": [
        "model.save('mnist_model')\n",
        "!tflite_convert --saved_model_dir=mnist_model --output_file=mnist_model.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfqM5syYP-IO"
      },
      "source": [
        "Save the labels as a plain text file, one label per row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsAlv2bsP-IP"
      },
      "outputs": [],
      "source": [
        "labels = list('0123456789')\n",
        "with open('mnist_labels.txt', 'w') as f:\n",
        "    for label in labels[:-1]:\n",
        "        f.write(label + '\\n')\n",
        "    f.write(labels[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yamLd-HKQ2KI"
      },
      "source": [
        "#### Download the model and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fag_cmckQ2KJ"
      },
      "source": [
        "Now download your model (`mnist_model.tflite`) and labels (`mnist_labels.txt`) from the **Files** pane on the left:\n",
        "* To download a file, *right-click* on the name of the file in the pane and select *Download*. (See [this answer](https://stackoverflow.com/questions/48774285/how-to-download-file-created-in-colaboratory-workspace/53860114#53860114) for more details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdRnzGsqxWfl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVFL-9D7P-IR"
      },
      "source": [
        "## Deploy the model with PalletML <a name=\"deploy\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13d3o3pP-IR"
      },
      "source": [
        "PalletML is a no-code platform that turns image classification models into mobile apps. You can learn more about it on the [website](http://palletml.com). (Currently supports Android, iOS coming soon).\n",
        "\n",
        "Let's use Pallet to deploy your model as a shareable app:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XnjMInzHk_9"
      },
      "source": [
        "1. **Install Pallet** from the Google Play Store\n",
        "\n",
        "    <a href=\"https://play.google.com/store/apps/details?id=com.palletml.app\"><img width=180 src=\"https://drive.google.com/uc?export=view&id=1Vbb_TAvaTJFZ8kBIA6kk-NpcF6y1ECZY\"/></a>\n",
        "\n",
        "    and **Sign Up** to create a new account\n",
        "\n",
        "    <img width=240 src=\"https://drive.google.com/uc?export=view&id=1STRSC9feaSmSQfsvD3rsG8Mf__9gDC2M\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNe9gX7VHk_9"
      },
      "source": [
        "2. **In your computer browser**, **visit [app.palletml.com](http://app.palletml.com)** in a new tab and **Log In** to the account you just created.\n",
        "\n",
        "    <img width=720 src=\"https://drive.google.com/uc?export=view&id=1YHv2gYQn7eF8U2x-42ZZhDhf_-yZcoG7\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBpgnRnEHk_-"
      },
      "source": [
        "3. Every model you deploy with Pallet belongs to a Project. **Create a New Project** for your model.\n",
        "\n",
        "    <img width=720 src=\"https://drive.google.com/uc?export=view&id=1SJzGrI0xGDfBkHQfyET1W3S7A5NHV3qd\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_040OC7eHlAA"
      },
      "source": [
        "4. **Choose a name** for your project and click **Create**.\n",
        "\n",
        "    <img width=720 src=\"https://drive.google.com/uc?export=view&id=12WLce4m-Jzf14tk5Enfh_CqjO75M0bR5\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ctOlPSHlAB"
      },
      "source": [
        "5. **Browse** or **Drag & Drop** your model and labels, then click **Upload**.\n",
        "\n",
        "    <img width=720 src=\"https://drive.google.com/uc?export=view&id=16Nm8Js3bJ05BNhir9MBspKFgJdE2kfz9\"/>\n",
        "    <img width=720 src=\"https://drive.google.com/uc?export=view&id=1T3tWSMoL5ueYMpCW-8GVpYiq-QMeSuf4\"/>\n",
        "    \n",
        "    Once the upload finishes, your model has been deployed âœ…."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNNsBf2UHlAC"
      },
      "source": [
        "6. **Return** to the **Pallet app**, navigate to your **Profile ðŸ‘¤**, and **pull to refresh** your list of Projects.\n",
        "\n",
        "    Your new Project will appear. âœ¨\n",
        "    \n",
        "    <img width=230 src=\"https://drive.google.com/uc?export=view&id=1wzyx1-ZmjDBB7nrTUOZtbtdoKFdEAJ-5\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLpE0J54HlAC"
      },
      "source": [
        "7. With Pallet, most image classification models work out of the box, but in this case we need to configure your Project to **preprocess** input images according to your model's expectations: with **inversion** and **grayscale**. \n",
        "\n",
        "    **Tap** your Project to open a detailed view. \n",
        "\n",
        "    Then **tap** the **Edit** icon to access Project **Settings**.\n",
        "\n",
        "    <img width=240 src=\"https://drive.google.com/uc?export=view&id=1WDIiM2i7laAqnN7aSwQw1wc1a8GYTcsV\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wZT_R69HlAC"
      },
      "source": [
        "8. Under *Input Settings*:\n",
        "\n",
        "    Toggle the **Invert Colors** switch to **On**.\n",
        "\n",
        "    Toggle the **Grayscale** switch to **On**.\n",
        "\n",
        "    <img width=240 src=\"https://drive.google.com/uc?export=view&id=1pLuro6ADZDWxvZkJVeVvmd8DA80L4l95\"/>    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVGv_oyTHlAD"
      },
      "source": [
        "9. Tap **Update** to save these settings. \n",
        "\n",
        "    <img width=240 src=\"https://drive.google.com/uc?export=view&id=1PYE2SwyXS9o_HtUanfLWOPaAMo1rXo4u\"/>    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09A8NU6OHlAD"
      },
      "source": [
        "10. Now **Launch** your app ðŸš€\n",
        "\n",
        "    Test drive your model by **Drawing** different digits to see how well it performs.\n",
        "    \n",
        "    <span>(For best results, leave a little space around the sides, just like the images your model was trained on&nbsp;&nbsp;<img width=28 src=\"https://drive.google.com/uc?export=view&id=1RBp8RH0c1NO-hc2vkkcoJuHrm6yiGU67\"/>)</span>\n",
        "\n",
        "    <img width=220 src=\"https://drive.google.com/uc?export=view&id=14iwWXap4SlfH-9NABzYLUj70UFxSmYH5\"/>  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
